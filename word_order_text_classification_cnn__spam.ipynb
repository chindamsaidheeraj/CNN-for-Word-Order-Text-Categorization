{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU34v-ODxGm-"
      },
      "source": [
        "Effective Use of Word Order for Text Categorization with Convolutional Neural Networks\n",
        " \n",
        "https://arxiv.org/abs/1412.1058\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install birdseye "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGr5haAFxtFO",
        "outputId": "9309e8ae-f3ad-4c7e-dfc6-ed588372847a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting birdseye\n",
            "  Downloading birdseye-0.9.4-py2.py3-none-any.whl (716 kB)\n",
            "\u001b[K     |████████████████████████████████| 716 kB 19.5 MB/s \n",
            "\u001b[?25hCollecting outdated\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting flask-humanize\n",
            "  Downloading Flask-Humanize-0.3.0.tar.gz (5.9 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from birdseye) (1.4.42)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from birdseye) (1.5.2)\n",
            "Collecting cheap-repr\n",
            "  Downloading cheap_repr-0.5.1-py2.py3-none-any.whl (12 kB)\n",
            "Collecting littleutils>=0.2\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from birdseye) (1.1.4)\n",
            "Collecting asttokens\n",
            "  Downloading asttokens-2.1.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens->birdseye) (1.15.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->birdseye) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->birdseye) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask->birdseye) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->birdseye) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->birdseye) (2.0.1)\n",
            "Requirement already satisfied: humanize>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from flask-humanize->birdseye) (0.5.1)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.7/dist-packages (from outdated->birdseye) (57.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated->birdseye) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->outdated->birdseye) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated->birdseye) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated->birdseye) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated->birdseye) (2.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->birdseye) (2.0.0.post0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->birdseye) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->birdseye) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->birdseye) (4.1.1)\n",
            "Building wheels for collected packages: littleutils, flask-humanize\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7047 sha256=dae022833d341e96895962d1e8d7ce255e447a2880a44b0564a0803167e4fb11\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "  Building wheel for flask-humanize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-humanize: filename=Flask_Humanize-0.3.0-py3-none-any.whl size=3642 sha256=621a490d97746f3fb0d63ec18ac2459688aa42e6f39303244b75a1d41b7e1c0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/92/82/b38683844f7d77443b1e9d89e61898c5de0683412b597d90f5\n",
            "Successfully built littleutils flask-humanize\n",
            "Installing collected packages: littleutils, outdated, flask-humanize, cheap-repr, asttokens, birdseye\n",
            "Successfully installed asttokens-2.1.0 birdseye-0.9.4 cheap-repr-0.5.1 flask-humanize-0.3.0 littleutils-0.2.2 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2avqnjAFdPHw",
        "outputId": "e708fd6a-29a6-441a-81cb-34e613f764b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 50 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.50.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (2.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.38.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KoZiD5etxGnA"
      },
      "outputs": [],
      "source": [
        "%load_ext birdseye\n",
        "%config BirdsEyeMagics.port = 7778"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4LsIB0N6xGnC"
      },
      "outputs": [],
      "source": [
        "import tarfile,os,sys, re\n",
        "is_eager_exec_init=False\n",
        "import psutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxIo6VE4xGnC",
        "outputId": "0729bf71-8f94-447c-bdf5-00981ef2858e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import sklearn\n",
        "\n",
        "# Use spacy to remove stop words first\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBNqCN6ayrSB",
        "outputId": "bc93bda5-be23-4ec9-d213-0e51c91a5466"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.60.0.tar.gz (38 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.60.0-py3-none-any.whl size=31285 sha256=8da2a4653b8ecb603b1e147f5073438eaba184d6de02a70fab8a031a8fdb1189\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/2b/fb/326e30d638c538e69a5eb0aa47f4223d979f502bbdb403950f\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.60.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmZOzdv9xGnD",
        "outputId": "40396958-94ae-49a4-f957-cfc4a3b7c5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 838.14 MiB, increment: 0.00 MiB\n"
          ]
        }
      ],
      "source": [
        "%load_ext memory_profiler\n",
        "%memit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU1C4a_HxGnE"
      },
      "source": [
        "Setup different variables in order to be able to reuse \n",
        "- data loading\n",
        "- data preparation steps later on when setting up the model. (defined later on) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mTQJQnyvxGnE"
      },
      "outputs": [],
      "source": [
        "is_data_already_loaded = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrgcPHYxxGnF"
      },
      "source": [
        "\n",
        "imdb dataset should be stored in /datasets dir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTjNPUGvxGnF"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "if not is_data_already_loaded:\n",
        "    test_neg_files = []\n",
        "    test_pos_files = []\n",
        "    train_neg_files = []\n",
        "    train_pos_files = []\n",
        "\n",
        "    with tarfile.open('/content/aclImdb_v1.tar.gz') as tar:\n",
        "        for mbr in tar.getmembers():\n",
        "            matches = re.findall('/test/neg/.*\\.txt',mbr.name)\n",
        "            if len(matches)==1:\n",
        "                f=tar.extractfile(mbr)\n",
        "                content=f.read()        \n",
        "                test_neg_files.append((mbr,content))\n",
        "            matches = re.findall('/test/pos/.*\\.txt',mbr.name)\n",
        "            if len(matches)==1:\n",
        "                f=tar.extractfile(mbr)\n",
        "                content=f.read()  \n",
        "                test_pos_files.append((mbr, content))\n",
        "            matches = re.findall('/train/neg/.*\\.txt',mbr.name)\n",
        "            if len(matches)==1:\n",
        "                f=tar.extractfile(mbr)\n",
        "                content=f.read()        \n",
        "                train_neg_files.append((mbr,content))\n",
        "            matches = re.findall('/train/pos/.*\\.txt',mbr.name)\n",
        "            if len(matches)==1:\n",
        "                f=tar.extractfile(mbr)\n",
        "                content=f.read()  \n",
        "                train_pos_files.append((mbr, content))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QPe-HjKAxGnG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c452c2ce-0dd2-4b88-9f86-f37c3890c7e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nif not is_data_already_loaded:\\n    train_neg = [txt.decode(\"utf-8\")  for file,txt in train_neg_files]\\n    train_pos = [txt.decode(\"utf-8\")  for file,txt in train_pos_files]\\n\\n    test_neg = [txt.decode(\"utf-8\")  for file,txt in test_neg_files]\\n    test_pos = [txt.decode(\"utf-8\")  for file,txt in test_pos_files]\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "'''\n",
        "if not is_data_already_loaded:\n",
        "    train_neg = [txt.decode(\"utf-8\")  for file,txt in train_neg_files]\n",
        "    train_pos = [txt.decode(\"utf-8\")  for file,txt in train_pos_files]\n",
        "\n",
        "    test_neg = [txt.decode(\"utf-8\")  for file,txt in test_neg_files]\n",
        "    test_pos = [txt.decode(\"utf-8\")  for file,txt in test_pos_files]\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "datasource=pd.read_csv('/content/spam_train.csv')\n",
        "source_data=[]\n",
        "Label_data=[]\n",
        "for index, row in datasource.iterrows():\n",
        "  source_data.append(row['data'])\n",
        "  Label_data.append(row['b_labels'])"
      ],
      "metadata": {
        "id": "jzwuSXfLT7nx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasourc_test=pd.read_csv('/content/spam_test.csv')\n",
        "test_data=[]\n",
        "Label_test=[]\n",
        "for index, row in datasourc_test.iterrows():\n",
        "  test_data.append(row['data'])\n",
        "  Label_test.append(row['b_labels'])"
      ],
      "metadata": {
        "id": "17zkyei3TMMu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Label_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_jtqYN7UBvL",
        "outputId": "c37e1ea1-bc3d-4b19-ec39-80a862787705"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "F8iPRZZ7xGnH"
      },
      "outputs": [],
      "source": [
        "vocab_nb = 20000\n",
        "\n",
        "def clean_docs(docs):\n",
        "    # clean docs by:\n",
        "    # - removing stop words\n",
        "    docs_wtho_stop = []\n",
        "    for raw_doc in docs:\n",
        "        doc = nlp(raw_doc)\n",
        "        doc_wtho_stop = \"\"\n",
        "        for tok in doc:\n",
        "            if not tok.is_stop:\n",
        "                doc_wtho_stop = doc_wtho_stop +tok.text+ \" \"\n",
        "        docs_wtho_stop.append(doc_wtho_stop)\n",
        "    return docs_wtho_stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Dr26mwJCxGnH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer, one_hot\n",
        "#from tensorflow.keras.backend import one_hot, get_session, set_session\n",
        "from tensorflow.compat.v1.keras.backend import set_session, one_hot, get_session\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D,MaxPool1D, Activation, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2, l1\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
        "config.log_device_placement = True  # to log device placement (on which device the operation ran) \n",
        "# (nothing gets printed in Jupyter, only if you run it standalone)\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "set_session(sess)"
      ],
      "metadata": {
        "id": "ASfNyF7t25ah"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-YEFMBogxGnH"
      },
      "outputs": [],
      "source": [
        "def docs_to_sequences(docs, vocab_nb=20000, max_length=None):\n",
        "    # create the tokenizer\n",
        "    t = Tokenizer(num_words=vocab_nb)\n",
        "    # fit the tokenizer on the documents\n",
        "    t.fit_on_texts(docs)\n",
        "    # create each doc as a list of integer indices\n",
        "    docs_seq_int = t.texts_to_sequences(docs)\n",
        "   # print(docs_seq_int)\n",
        "    \n",
        "    \n",
        "    doc_nb = len(docs_seq_int)\n",
        "    if max_length==None:\n",
        "        max_length = len(sorted(docs_seq_int,key=len, reverse=True)[0])\n",
        "        #print(\"max_lenght computed:\",max_length)\n",
        "    #print(\"max_length:\",max_length)\n",
        "    \n",
        "    # Create a dense array of shape (doc_nb,max_length). \n",
        "    # Each cell contains a int (the indice of word)\n",
        "    \n",
        "    docs_seq_dense = []\n",
        "    docs_seq_array = np.zeros((doc_nb,max_length),dtype=np.int16)\n",
        "    for idx, seq_int in enumerate(docs_seq_int):\n",
        "        padded_seq_int = seq_int+[0]*(max_length-len(seq_int))\n",
        "        doc_array = np.array(padded_seq_int, dtype=np.int16)\n",
        "        docs_seq_array[idx]=doc_array[:max_length]\n",
        "\n",
        "    return docs_seq_array\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5e7UWlppxGnI"
      },
      "outputs": [],
      "source": [
        "def categorical_generator(X, y, batch_size=64,vocab_nb=20000):\n",
        "    # Must be able to iterate many times on the same X/y , for instance while training with many epochs.\n",
        "    i=0\n",
        "    while True:\n",
        "        #print(i)\n",
        "       # print(i)\n",
        "        if i >= len(X):\n",
        "            i=0\n",
        "        tmp_X = X[i:batch_size+i]\n",
        "        #print(tmp_X)\n",
        "        batch_X= to_categorical(tmp_X,num_classes=vocab_nb)\n",
        "        #print(batch_X)\n",
        "        batch_y = y[i:batch_size+i]\n",
        "        #print(\"cat gen: \", len(batch_X), len(batch_y))\n",
        "        yield batch_X, batch_y\n",
        "        i+=batch_size       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2OKB0rIxGnI"
      },
      "source": [
        "## Toy Test data preparation\n",
        "\n",
        "Data preparation logic is tested on a very small toy data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBYBIvJwxGnI",
        "outputId": "bd176d1f-a6ef-4a77-83a4-e01c3568583e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  0  0]\n",
            " [ 5  6  5  2  0  0  0  0]\n",
            " [ 7  2 10  0  0  0  0  0]\n",
            " [11  6  1  0  0  0  0  0]\n",
            " [12  3  1  0  0  0  0  0]\n",
            " [ 4  3  0  0  0  0  0  0]\n",
            " [13  0  0  0  0  0  0  0]\n",
            " [ 4  8  0  0  0  0  0  0]\n",
            " [14  2  1 15 16  7  3  9]\n",
            " [ 9  1  0  0  0  0  0  0]\n",
            " [17 18  4  8  0  0  0  0]]\n"
          ]
        }
      ],
      "source": [
        "do_toy_test=True\n",
        "\n",
        "if do_toy_test:\n",
        "    toy_vocab_nb = 20\n",
        "    toy_max_sent_len = 8\n",
        "  \n",
        "    docs = ['Well done!',\n",
        "            'Good work, good effort',\n",
        "            'Great effort guys',\n",
        "            'nice work my friend',\n",
        "            'Excellent job my friend!',\n",
        "            'What a poor job !! ',\n",
        "            'This is a shame',\n",
        "            'You are a poor guy',\n",
        "            'Fantastic effort my friend and brother, hell of a great job for ever I like it',\n",
        "            'I like you so much my friend',\n",
        "            'You worked so bad poor guy']\n",
        "\n",
        "    cleaned_docs = clean_docs(docs)\n",
        "    #print(cleaned_docs)\n",
        "    doc_sequences = docs_to_sequences(cleaned_docs, max_length=toy_max_sent_len, vocab_nb=toy_vocab_nb)\n",
        "    print(doc_sequences)\n",
        "    #print(type(doc_sequences))\n",
        "    np.save(\"./tst\",doc_sequences)\n",
        "    tmp_array = np.load(\"./tst.npy\")\n",
        "    #print(tmp_array)\n",
        "    \n",
        "    labels=[1,1,0,1,1,0,0,0,1,0,1]\n",
        "#%memit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR4NIJ03K1eR",
        "outputId": "94f2f997-3bc8-4372-83c6-2fdbf15bbd91"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  0  0]\n",
            " [ 5  6  5  2  0  0  0  0]\n",
            " [ 7  2 10  0  0  0  0  0]\n",
            " [11  6  1  0  0  0  0  0]\n",
            " [12  3  1  0  0  0  0  0]\n",
            " [ 4  3  0  0  0  0  0  0]\n",
            " [13  0  0  0  0  0  0  0]\n",
            " [ 4  8  0  0  0  0  0  0]\n",
            " [14  2  1 15 16  7  3  9]\n",
            " [ 9  1  0  0  0  0  0  0]\n",
            " [17 18  4  8  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ugmNUyAsxGnJ"
      },
      "outputs": [],
      "source": [
        "if do_toy_test:\n",
        "    #print(doc_sequences,labels)\n",
        "    toy_batch_size=2\n",
        "    nb_iter=doc_sequences.shape[0] // toy_batch_size\n",
        "    j=0\n",
        "    nb_epoch=0\n",
        "    for batch_x, batch_y in categorical_generator(doc_sequences,labels,batch_size=toy_batch_size,vocab_nb=toy_vocab_nb):\n",
        "       # print(type(batch_x),batch_x.shape)\n",
        "        #print(batch_y)\n",
        "        #print(batch_x)\n",
        "        assert (len(batch_x)<=toy_batch_size) & (len(batch_y) <=toy_batch_size)\n",
        "        #print(nb_epoch,j,nb_iter)\n",
        "        if j > nb_iter:\n",
        "            j=0\n",
        "            nb_epoch+=1\n",
        " #       if batch_x.shape[0]<test_batch_size:\n",
        " #           nb_epoch+=1\n",
        "        if nb_epoch ==3:\n",
        "            break        \n",
        "        j+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc_sequences[:\n",
        "                    -2],labels[:-2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK1BPwdtMReZ",
        "outputId": "98f8e03a-aabb-472c-f96e-1c5cbf0684f6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  0  0]\n",
            " [ 5  6  5  2  0  0  0  0]\n",
            " [ 7  2 10  0  0  0  0  0]\n",
            " [11  6  1  0  0  0  0  0]\n",
            " [12  3  1  0  0  0  0  0]\n",
            " [ 4  3  0  0  0  0  0  0]\n",
            " [13  0  0  0  0  0  0  0]\n",
            " [ 4  8  0  0  0  0  0  0]\n",
            " [14  2  1 15 16  7  3  9]] [1, 1, 0, 1, 1, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-iH5s18xGnJ",
        "outputId": "fdf9fc94-6a15-46d5-98a0-63dee91fc80c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb steps per epoch 3.6666666666666665\n",
            "Epoch 1/10\n",
            "4/3 - 1s - loss: 0.6768 - acc: 0.6667 - val_loss: 0.6552 - val_acc: 1.0000\n",
            "Epoch 2/10\n",
            "4/3 - 0s - loss: 0.6817 - acc: 0.6667 - val_loss: 0.6546 - val_acc: 1.0000\n",
            "Epoch 3/10\n",
            "4/3 - 0s - loss: 0.6697 - acc: 0.6667 - val_loss: 0.6548 - val_acc: 1.0000\n",
            "Epoch 4/10\n",
            "4/3 - 0s - loss: 0.6696 - acc: 0.6667 - val_loss: 0.6546 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "4/3 - 0s - loss: 0.6756 - acc: 0.6667 - val_loss: 0.6541 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "4/3 - 0s - loss: 0.6654 - acc: 0.6667 - val_loss: 0.6543 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "4/3 - 0s - loss: 0.6646 - acc: 0.6667 - val_loss: 0.6542 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "4/3 - 0s - loss: 0.6704 - acc: 0.6667 - val_loss: 0.6538 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "4/3 - 0s - loss: 0.6614 - acc: 0.6667 - val_loss: 0.6541 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "4/3 - 0s - loss: 0.6600 - acc: 0.6667 - val_loss: 0.6540 - val_acc: 0.5000\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_2 (Conv1D)            (None, 7, 1)              41        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 3, 1)              0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 45\n",
            "Trainable params: 45\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "if do_toy_test:\n",
        "    toy_batch_size=3\n",
        "    toy_model = Sequential([\n",
        "        Conv1D(1, 2, strides=1, activation='relu', kernel_initializer='he_normal', bias_initializer='zeros',input_shape=(toy_max_sent_len,toy_vocab_nb), kernel_regularizer=l2(0.01)),\n",
        "        MaxPool1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(1, kernel_initializer='he_normal', bias_initializer='zeros', activation='sigmoid')\n",
        "    ])\n",
        "    toy_model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    tb_cb = TensorBoard(log_dir='./logs-test', histogram_freq=0, batch_size=4, \n",
        "                write_graph=True, write_grads=True, )\n",
        "    \n",
        "    test_steps_per_epoch=len(doc_sequences)/toy_batch_size\n",
        "    print(\"nb steps per epoch\", test_steps_per_epoch)\n",
        "    \n",
        "    train_cat_gen = categorical_generator(doc_sequences[:-2],labels[:-2],batch_size=toy_batch_size,vocab_nb=toy_vocab_nb)\n",
        "    xval_cat_gen = categorical_generator(doc_sequences[-2:],labels[-2:],batch_size=toy_batch_size,vocab_nb=toy_vocab_nb)\n",
        "    toy_history = toy_model.fit_generator(train_cat_gen, steps_per_epoch=test_steps_per_epoch,epochs=10, validation_data=xval_cat_gen,validation_steps=1 ,verbose=2, callbacks=[tb_cb])\n",
        "    \n",
        "    toy_model.summary()\n",
        "    toy_model.save('./toy_model_v1')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCkHHCvyxGnJ"
      },
      "source": [
        "## Prepare real data\n",
        "\n",
        "As this process is time consuming, prepared data are stored as numpy arrays. \n",
        "Var is_data_already_prepared is used to control if we need to prepare the data again. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "04qtsGvVxGnJ"
      },
      "outputs": [],
      "source": [
        "# As data as already been prepared, i will be omitted\n",
        "is_data_already_prepared=False\n",
        "max_sent_len = 30\n",
        "if not is_data_already_prepared:\n",
        "    \n",
        "    cleaned_train_neg = clean_docs(source_data)\n",
        "    seq_train_neg = docs_to_sequences(cleaned_train_neg, max_length=max_sent_len)  \n",
        "    '''  \n",
        "    cleaned_train_pos = clean_docs(train_pos)\n",
        "    seq_train_pos = docs_to_sequences(cleaned_train_pos, max_length=max_sent_len)\n",
        "    np.save('./seq_train_neg',seq_train_neg)\n",
        "    '''\n",
        "    np.save('./source_data',source_data)\n",
        "    \n",
        "    cleaned_test_neg = clean_docs(test_data)\n",
        "    seq_test_neg = docs_to_sequences(cleaned_test_neg,max_length=max_sent_len)\n",
        "\n",
        "    '''\n",
        "    cleaned_test_pos = clean_docs(test_pos)\n",
        "    seq_test_pos = docs_to_sequences(cleaned_test_pos, max_length=max_sent_len)\n",
        "    np.save('./seq_test_neg',seq_test_neg)\n",
        "    np.save('./seq_test_pos',seq_test_pos)\n",
        "    '''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sent_len = 30"
      ],
      "metadata": {
        "id": "tdmhFLI1eW1y"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vVOBalkxGnJ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "is_data_already_prepared=True\n",
        "if is_data_already_prepared:\n",
        "    seq_test_neg = np.load('./seq_test_neg.npy')\n",
        "    seq_test_pos = np.load('./seq_test_pos.npy')\n",
        "    seq_train_neg = np.load('./seq_train_neg.npy')\n",
        "    seq_train_pos = np.load('./seq_train_pos.npy')\n",
        "    print(\"prepared data loaded\")\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqwiJKpjxGnK"
      },
      "outputs": [],
      "source": [
        "# Print shapes of different prepared datasets\n",
        "'''\n",
        "seq_train_neg[:].shape, seq_train_pos[:].shape,seq_test_neg.shape, seq_test_pos.shape\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "EjfO6uK3xGnK"
      },
      "outputs": [],
      "source": [
        "#seq_train_neg.shape, type(seq_test_neg)\n",
        "train_pos = np.ones((seq_train_neg.shape[0]))\n",
        "train_neg = np.zeros((seq_train_neg.shape[0]))\n",
        "\n",
        "#test_pos = np.ones((seq_test_neg.shape[0]))\n",
        "#test_neg = np.zeros((seq_test_neg.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8xDLYKGhBfe",
        "outputId": "487604a2-3a9a-4651-d85a-caae8052ff83"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2rgs4eRxGnK"
      },
      "outputs": [],
      "source": [
        "#seq_train = seq_train_neg + seq_train_pos\n",
        "'''\n",
        "seq_train = np.append(seq_train_neg,seq_train_pos,axis=0)\n",
        "seq_test = np.append(seq_test_neg,seq_test_pos,axis=0)\n",
        "train_label = np.append(train_neg,train_pos,axis=0)\n",
        "test_label = np.append(test_neg,test_pos,axis=0)\n",
        "assert np.any(train_label[:12500]==0)\n",
        "assert np.any(train_label[1250:]==1.)\n",
        "assert np.any(test_label[:12500]==0)\n",
        "assert np.any(test_label[12500:]==1.)\n",
        "seq_train_neg.shape, seq_train.shape,seq_test.shape,train_label.shape, test_label.shape\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZCfzesfxGnK"
      },
      "source": [
        "### Prepare validation data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "h4AHIOcpxGnK"
      },
      "outputs": [],
      "source": [
        "import sklearn.model_selection\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(Label_data)\n",
        "labels = np.array(Label_data)\n",
        "type(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ7HCW29gYX3",
        "outputId": "0694774b-622d-4949-8421-bc633600cd17"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or6N1g6LxGnL",
        "outputId": "d89cac6d-328b-47f4-8d80-98bf16123545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train & xval shapes: (4136, 30) (1035, 30) (4136,) (1035,)\n"
          ]
        }
      ],
      "source": [
        "xval_rate=0.2\n",
        "X_train, X_xval, y_train, y_xval = sklearn.model_selection.train_test_split(seq_train_neg,labels, test_size=0.2)\n",
        "#assert X_train.shape==(seq_train.shape[0] * (1-xval_rate),seq_train.shape[1])\n",
        "print(\"train & xval shapes:\", X_train.shape,X_xval.shape, y_train.shape, y_xval.shape)\n",
        "\n",
        "#print(X_xval.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_nb=20000"
      ],
      "metadata": {
        "id": "sRaTNBYCjndu"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ytQi0v0xGnL"
      },
      "source": [
        "## Create model and train it\n",
        "\n",
        "### shallow CNN model\n",
        "\n",
        "in order to setup the model with agility, train_nb and xval_nb can be specified with small numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ppB7Ll7xGnL",
        "outputId": "97eddce8-80a3-4244-869c-7a022afad7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_3 (Conv1D)            (None, 29, 1)             40001     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 14, 1)             0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 14)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 15        \n",
            "=================================================================\n",
            "Total params: 40,016\n",
            "Trainable params: 40,016\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "nb steps per epoch 53\n",
            "53/53 [==============================] - 20s 377ms/step - loss: 0.6601 - acc: 0.8677 - val_loss: 0.6306 - val_acc: 0.8718\n"
          ]
        }
      ],
      "source": [
        "do_train=True\n",
        "if do_train:\n",
        "\n",
        "    batch_size=78\n",
        "    epochs_nb = 1\n",
        "    model = Sequential([\n",
        "        Conv1D(1, 2, strides=1, activation='relu', kernel_initializer='he_normal', \n",
        "               bias_initializer='zeros',input_shape=(max_sent_len,vocab_nb),\n",
        "                kernel_regularizer=l2(0.01)),\n",
        "        MaxPool1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(1, kernel_initializer='he_normal', bias_initializer='zeros',activation='sigmoid')\n",
        "    ])\n",
        "    rmsprop = RMSprop(lr=1e-3)\n",
        "    # results on sgd are by far worst than rmsprop\n",
        "    sgd = SGD(lr=1e-3, momentum=0.9)\n",
        "    \n",
        "    model.compile(optimizer=rmsprop,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    cb_list = [\n",
        "        ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=10),\n",
        "        TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, \n",
        "                write_graph=True, write_grads=True, )\n",
        "    ]\n",
        "    \n",
        "    # used to train only on a subset while configuring the network architecture\n",
        "    train_nb = 128\n",
        "    # comment next line if you want to work on a smaller dataset\n",
        "    train_nb = None\n",
        "    if not train_nb:\n",
        "        train_nb = len(X_train)\n",
        "    xval_nb = 20\n",
        "    # comment next line if you want to work on a smaller dataset\n",
        "    xval_nb = None\n",
        "    if not xval_nb:\n",
        "        xval_nb = len(X_xval)\n",
        "\n",
        "    steps_per_epoch=train_nb// batch_size\n",
        "    print(\"nb steps per epoch\", steps_per_epoch)\n",
        "    train_cat_gen = categorical_generator(X_train[:train_nb],y_train[:train_nb],batch_size=batch_size,vocab_nb=vocab_nb)\n",
        "    xval_cat_gen = categorical_generator(X_xval[:xval_nb],y_xval[:xval_nb],batch_size=batch_size,vocab_nb=vocab_nb)\n",
        "    history = model.fit_generator(train_cat_gen, steps_per_epoch=steps_per_epoch,epochs=epochs_nb, \n",
        "                                  validation_data=xval_cat_gen,\n",
        "                                  validation_steps=1 ,verbose=1, callbacks=cb_list)\n",
        "    \n",
        "    \n",
        "    model.save('./model_v1.hdf5')\n",
        "    model.save_weights('./model_w_v1')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createmodel():\n",
        "  model = Sequential([\n",
        "        Conv1D(1, 2, strides=1, activation='relu', kernel_initializer='he_normal', \n",
        "               bias_initializer='zeros',input_shape=(max_sent_len,vocab_nb),\n",
        "                kernel_regularizer=l2(0.01)),\n",
        "        MaxPool1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(1, kernel_initializer='he_normal', bias_initializer='zeros',activation='sigmoid')\n",
        "       ])\n",
        "  rmsprop = RMSprop(lr=1e-3)\n",
        "    # results on sgd are by far worst than rmsprop\n",
        "  sgd = SGD(lr=1e-3, momentum=0.9)\n",
        "    \n",
        "  model.compile(optimizer=rmsprop,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  model.summary()\n",
        "    \n",
        "  cb_list = [\n",
        "        ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=10),\n",
        "        TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, \n",
        "                write_graph=True, write_grads=True, )\n",
        "    ]"
      ],
      "metadata": {
        "id": "9e0NfbrdpkkV"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGYDvIX_xGnL"
      },
      "source": [
        "### Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "DKTWARQ7xGnM"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py"
      ],
      "metadata": {
        "id": "rr-E6JlnpMSH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "SGCWWecaxGnM",
        "outputId": "d8d6f8e7-c5a2-425c-af65-9da634952454"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi1jCDEuxGnM"
      },
      "source": [
        "## Evaluate on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "YgaSMmWLxGnM"
      },
      "outputs": [],
      "source": [
        "#from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37D_H62kxGnM"
      },
      "outputs": [],
      "source": [
        "#loaded_model = load_model('./model_v1.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install h5py"
      ],
      "metadata": {
        "id": "2d69SBc0smkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmX253owxGnM",
        "outputId": "b5864610-7f6b-456f-d1eb-61800c76a8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6447 - acc: 0.8571\n",
            "test_loss: 0.6446771025657654  test accuracy: 0.85714287\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6492 - acc: 0.8095\n",
            "test_loss: 0.6491934061050415  test accuracy: 0.8095238\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6292 - acc: 0.9048\n",
            "test_loss: 0.6291744709014893  test accuracy: 0.9047619\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6381 - acc: 0.8571\n",
            "test_loss: 0.6380521059036255  test accuracy: 0.85714287\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6168 - acc: 0.9524\n",
            "test_loss: 0.616775393486023  test accuracy: 0.95238096\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6161 - acc: 0.9048\n",
            "test_loss: 0.6161391139030457  test accuracy: 0.9047619\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6243 - acc: 0.9048\n",
            "test_loss: 0.6243162751197815  test accuracy: 0.9047619\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6118 - acc: 0.9524\n",
            "test_loss: 0.6118364334106445  test accuracy: 0.95238096\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6213 - acc: 0.9524\n",
            "test_loss: 0.6213335394859314  test accuracy: 0.95238096\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6507 - acc: 0.7619\n",
            "test_loss: 0.6506860852241516  test accuracy: 0.7619048\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6326 - acc: 0.8571\n",
            "test_loss: 0.6326212882995605  test accuracy: 0.85714287\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6037 - acc: 1.0000\n",
            "test_loss: 0.6036669015884399  test accuracy: 1.0\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6147 - acc: 0.9524\n",
            "test_loss: 0.6146584153175354  test accuracy: 0.95238096\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6296 - acc: 0.9048\n",
            "test_loss: 0.6295729875564575  test accuracy: 0.9047619\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6717 - acc: 0.7143\n",
            "test_loss: 0.6716629266738892  test accuracy: 0.71428573\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6270 - acc: 0.9048\n",
            "test_loss: 0.6270164847373962  test accuracy: 0.9047619\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6329 - acc: 0.8571\n",
            "test_loss: 0.6328848004341125  test accuracy: 0.85714287\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6324 - acc: 0.9048\n",
            "test_loss: 0.6324493885040283  test accuracy: 0.9047619\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6380 - acc: 0.8571\n",
            "test_loss: 0.6379961967468262  test accuracy: 0.85714287\n",
            "21/21 [==============================] - 0s 2ms/sample - loss: 0.6334 - acc: 0.9048\n",
            "test_loss: 0.6334272027015686  test accuracy: 0.9047619\n",
            "1/1 [==============================] - 0s 3ms/sample - loss: 0.6396 - acc: 1.0000\n",
            "test_loss: 0.6396077275276184  test accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "step = 20\n",
        "max_test_nb = seq_test_neg.shape[0]\n",
        "for i in range(0,max_test_nb,step):    \n",
        "    test_from = i\n",
        "    test_size=20\n",
        "    test_to = test_from + test_size+1\n",
        "    test_X= to_categorical(seq_test_neg[test_from:test_to],num_classes=vocab_nb)\n",
        "    test_y = Label_test[test_from:test_to]\n",
        "    \n",
        "    test_loss, test_acc = model.evaluate(test_X, test_y)\n",
        "    print('test_loss:', test_loss, ' test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kme45ANxGnN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxT7x_NmxGnN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}